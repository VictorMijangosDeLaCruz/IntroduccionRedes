{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b548a07",
   "metadata": {},
   "source": [
    "# Modo reverse en diferenciación automática\n",
    "\n",
    "El modo reverse, en contraste con el modo forward, obtiene las derivadas de una función compleja a partir de recorrer un grafo computacional en retroceso; i.e., desde las salidas de la función hacia las entradas. De esta forma, se calcula la derivada de las funciones de salida y se usan esas derivadas para las funciones en los nodos anteriores en el grafo usando la regla de la cadena para obtener las nuevas derivadas. \n",
    "\n",
    "Así, si $f_i$ es la función en un nodo del cual queremos obtener su derivada y si $f_{i+1}$ es la función de un nodo superiro, entonces la derivada en el modo reverse se obtiene como:\n",
    "\n",
    "$$\\frac{\\partial f_{i+1}}{\\partial x} = \\frac{\\partial f_{i+1}}{\\partial f_i} \\frac{\\partial f_i}{x}$$\n",
    "\n",
    "De esta forma, la derivación se propaga hacia atrás, generando una traza derivativa que para obtener las derivadas parciales sobre las entradas de la función. En este caso, el modo reverse obtiene el vector gradiente $\\nabla_x f_i$ para una de las salidas de la función; es decir, cada vez que corremos el modo reverse para obtener la diferenciación, obtenemos las derivadas parciales sobre todas las variables de entrada, pero sólo para una de las salidas.\n",
    "\n",
    "El modo reverse almacena las derivadas de las funciones de los nodos del grafo computacional a partir de variables específicas. En este caso, la variable de salida se le asigna un valor de 1, si es esa la salida sobre la que queremos derivar; de otra forma, le asignamos el valor 0 a las salidas que no nos interesen en ese momento. De igual forma, se puede iniciar con un vector distinto a los vectores base; en este caso, interpretamos el resultado del modo reverse como el producto de la matriz Jacobiana $J_f$ transpuesta por el vector.\n",
    "\n",
    "## Implementación de un ejemplo en modo forward\n",
    "\n",
    "Para ejemplificar el modo forward definiremos un grafo computacional que compute la función $b:\\mathbb{R}^3 \\to \\mathbb{R}$ dada como:\n",
    "\n",
    "$$b = x(y-z)^2$$\n",
    "\n",
    "En el grafo, definiremos tres nodos que nos servirán para computar la función final. Estos tres nodos son en orden los siguientes:\n",
    "\n",
    "$$a = y-z$$\n",
    "$$c = a^2$$\n",
    "$$b = xc$$\n",
    "\n",
    "Cada uno de estos nodos contiene una función más simple, cuyas derivadas son fáciles de estimar; asociaremos a cada nodo una variable con la respectiva derivada de la siguiente forma:\n",
    "\n",
    "$$c' = x$$\n",
    "$$a' = 2ac'$$\n",
    "$$x' = c$$\n",
    "$$y' = a'$$\n",
    "$$z' = -a'$$\n",
    "\n",
    "Dado que sólo tenemos una salida, la variable para este nodo de salida será siempre 1. Al final, con el modo reverse podemos obtener el vector gradiente correspondiente a la función en un solo paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ad27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseMode(object):\n",
    "    def forward(self, x, y, z):\n",
    "        # Define el avance en el grafo\n",
    "        a = y-z\n",
    "        c = a**2\n",
    "        b = x*c\n",
    "        \n",
    "        print(b)\n",
    "        return a,b,c\n",
    "    \n",
    "    def backward(self, x,y,z):\n",
    "        #Calcula los valores d ela función\n",
    "        a,b,c = self.forward(x,y,z)\n",
    "        #Incializa las salidas\n",
    "        db = 1\n",
    "        #Derivadas\n",
    "        dc = x\n",
    "        da = 2*a*dc\n",
    "        dx = c\n",
    "        dy = 1*da\n",
    "        dz = -1*da\n",
    "        \n",
    "        return dx, dy, dz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78908327",
   "metadata": {},
   "source": [
    "En el caso del modo reverse, antes de aplicar propiamente la diferenciación, debemos correr el grafo hacia adelante en el paso que llamamos 'forward'. Esto nos ayudará a obtener los valores que posteriormente podemos usar para los cálculos de las derivadas. En este caso, vemos que al correr la función hacia adelante obtenemos el resultado esperado bajo los valores de entrada determiandos. Asimismo, regresa los valores obtenidos en cada uno de los nodos, pues estos son los que nos interesarán para obtener la derivada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8298a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 8, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Genera el grafo computacional\n",
    "f = ReverseMode()\n",
    "#Corre la función hacia adeltante\n",
    "f.forward(2,5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f64ce2",
   "metadata": {},
   "source": [
    "Ahora podemos ejecutar el paso backward, que es donde el modo reverse obtiene el gradiente de la función. Como podemos ver, sólo basta correr una vez el modo reverse para obtener todo el vector gradiente, y por tanto, para obtener la derivada de toda la función en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04bf82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Gradiente de la función: [(4, 8, -8)]\n"
     ]
    }
   ],
   "source": [
    "#Aplica paso backward\n",
    "print('Gradiente de la función: [{}]'.format(f.backward(2,5,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b424d",
   "metadata": {},
   "source": [
    "El modo reverse es efectivo cuando se cuenta con una función $f: \\mathbb{R}^n \\to \\mathbb{R}^m$ tal que $m < n$, pues en este caso, realizará solo $m$ pasos para obtener la derivada de la función. El ejemplo anterior muestra este caso, puesto que al ser un funcional en que sólo se obtiene un valor de salida, basta correr sólo una vez el modo reverse para obtener el vector gradiente esperado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
